---
layout: post
title: AutoDL最佳实践
date: 2025-04-19 14:32:13
description: AutoDL最佳实践
tags: Debug Deploy
categories: Experience
tabs: true
---

# AutoDL最佳实践

因为课题需要，我展开了对AutoDL和[恒源云](https://gpushare.com/)平台的试用，恒源云请一定要[学生认证](https://gpushare.com/center/account/student)一下

[AutoDL文档](https://www.autodl.com/docs)

## 开始



## 克隆实例

在使用时发现，你租用的实例只有在**同一台服务器**（一般有8-10个GPU）有空闲的时候，你才能开机。

**是刚好！在！同一个服务器的！可怜的8-10张显卡！有！空！闲！**

完全不是人，伟大的AutoDL降临了伟大的**克隆实例**功能，可以完全克隆，克隆实例可以把系统和数据盘的东西克隆到同区

<img src="S:\Programming\Son4ta.github.io\Son4ta.github.io\assets\img\image-20250420155046472.png" alt="image-20250420155046472" style="zoom:75%;" />

[^伟大，无需多言，但是一天只有三次，别带滔博节奏]: 

## 跨实例复制

有人就要问了，主播主播，克隆实例虽然好用，但是就一天三次机会，万一克隆完还是被占了，还是太吃操作了。

在实际使用中，你的一堆实例真是不知道哪个能用，六冠王**跨实例复制**来了！

![image-20250420155813515](S:\Programming\Son4ta.github.io\Son4ta.github.io\assets\img\image-20250420155813515.png)

```shell
ubuntu:/etc/docker$ sudo rm daemon.json 
```
启动docker
```shell
 systemctl start docker
```
因为正常执行build大概率会因为网络问题翻车

所以先安装

[ERROR [internal\] load metadata for nvcr.io/nvidia/tensorrt:21.09-py3 · Issue #189 · ifzhang/ByteTrack (github.com)](https://github.com/ifzhang/ByteTrack/issues/189)

```sh
docker pull nvcr.io/nvidia/pytorch:21.09-py3 -–registry-mirror=https://mirror.iscas.ac.cn(国内镜像源地址)
```
启动docker
```
torchrun --standalone --nnodes 1 --nproc-per-node 1 vla-scripts/finetune.py \
  --vla_path openvla/openvla-7b \
  --data_root_dir /root/autodl-tmp/openvla/dataset/ \
  --dataset_name libero_goal_no_noops \
  --run_root_dir /root/autodl-tmp/openvla/log/ \
  --use_l1_regression True \
  --use_diffusion False \
  --use_film False \
  --num_images_in_input 2 \
  --use_proprio True \
  --batch_size 8 \
  --learning_rate 5e-4 \
  --num_steps_before_decay 100000 \
  --max_steps 150005 \
  --save_freq 10000 \
  --save_latest_checkpoint_only False \
  --image_aug True \
  --lora_rank 32 \
  --wandb_entity "UCAS" \
  --wandb_project "VLN"
  
  
usage: finetune.py [-h] [--config_path str] [--vla_path str]
                   [--data_root_dir str] [--dataset_name str]
                   [--run_root_dir str] [--adapter_tmp_dir str]
                   [--batch_size str] [--max_steps str] [--save_steps str]
                   [--learning_rate str] [--grad_accumulation_steps str]
                   [--image_aug str] [--shuffle_buffer_size str]
                   [--save_latest_checkpoint_only str] [--use_lora str]
                   [--lora_rank str] [--lora_dropout str]
                   [--use_quantization str] [--wandb_project str]
                   [--wandb_entity str] [--run_id_note str]

  
torchrun --standalone --nnodes 1 --nproc-per-node 1 vla-scripts/finetune.py \
  --vla_path /root/autodl-tmp/openvla/openvla-7b \
  --data_root_dir /root/autodl-tmp/openvla/dataset/modified_libero_rlds/ \
  --dataset_name libero_object_no_noops \
  --run_root_dir /root/autodl-tmp/openvla/log/ \
  --adapter_tmp_dir /root/autodl-tmp/openvla/log/ \
  --lora_rank 32 \
  --batch_size 2 \
  --grad_accumulation_steps 1 \
  --learning_rate 2.5e-4 \
  --image_aug True \
  --wandb_project "UCAS" \
  --wandb_entity "UCAS" \
  --save_steps 5000 \
  --max_steps 30000 \
  --save_latest_checkpoint_only true; /usr/bin/shutdown 
  
  torchrun --standalone --nnodes 1 --nproc-per-node 1 vla-scripts/finetune.py \
  --vla_path ./weight/openvla-7b \
  --data_root_dir ../modified_libero_rlds/ \
  --dataset_name libero_goal_no_noops \
  --run_root_dir ./log \
  --use_l1_regression True \
  --use_diffusion False \
  --use_film False \
  --num_images_in_input 2 \
  --use_proprio True \
  --batch_size 4 \
  --learning_rate 5e-4 \
  --num_steps_before_decay 100000 \
  --max_steps 150005 \
  --save_freq 10000 \
  --save_latest_checkpoint_only True \
  --image_aug True \
  --lora_rank 32

```

